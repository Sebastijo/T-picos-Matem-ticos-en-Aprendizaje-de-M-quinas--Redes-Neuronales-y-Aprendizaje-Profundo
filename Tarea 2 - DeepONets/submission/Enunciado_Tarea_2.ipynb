{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqFk5CBeLjN0"
      },
      "source": [
        "## **MA5606 Tópicos Matemáticos en Aprendizaje de Máquinas, Redes Neuronales y Aprendizaje Profundo**\n",
        "\n",
        "### **Tarea 2: Algoritmos de entrenamiento y aproximación de esperanzas condicionales**\n",
        "\n",
        "**Profesores: Claudio Muñoz y Joaquín Fontbona**\n",
        "\n",
        "**Auxiliares: Javier Maass y Diego Olguín**\n",
        "\n",
        "**Nombres integrantes: COMPLETAR**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3gTx7GbPsvw"
      },
      "source": [
        "**Instrucciones:**\n",
        "\n",
        "- **Fecha de entrega:** **31 de mayo de 2024, a las 23:59.**\n",
        "\n",
        "- **Importante:** Si trabaja desde el link de Google Colab debe hacer un copia en su Drive antes de trabajar, de lo contrario se podrían no guardar sus códigos.\n",
        "\n",
        "- Debe entregar un Jupyter Notebook (archivo .ipynb) con sus código en Python. Le pueden ser de mucha utilidad los códigos vistos en la actividad práctica.\n",
        "\n",
        "- Sus códigos deben estar comentados y ordenados. Además, en formato texto debe colocar todas sus conclusiones y resultados pedidos que deban ser redactados.\n",
        "\n",
        "- En todos los ejercicios se le pide hacer al menos un gráfico. Los gráficos que realicen deben ser claros, con títulos y nombres en los ejes, junto con leyendas si es que corresponde."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEl7z1gWLr7t"
      },
      "source": [
        "#### **Ejercicio 1: Algoritmo Adam**\n",
        "\n",
        "En el presente [artículo](https://arxiv.org/abs/1412.6980) se introduce el algoritmo de optimización estocástica Adam (por Adaptative Moment Estimation), el objetivo de este ejercicio es implementar dicho algoritmo y utilizarlo para entrenar redes neuronales, para ello se explorarán todos los detalles de implementación de una red neuronal, con ciertas simplificaciones.\n",
        "\n",
        "Utilizaremos Adam para entrenar una red neuronal de 1 capa oculta de $\\mathbb{R}$ en $\\mathbb{R}$, de ancho $batch_size$, con su realización dada por\n",
        "\n",
        "$$ \\Phi_\\theta (x) = W_2 \\cdot \\sigma (W_1 \\cdot x + b_1) + b_2 $$\n",
        "\n",
        "Consideraremos $\\sigma(x) = \\text{tanh}(x)$ y $\\theta = (W_1, b_1, W_2, b_2)$, $W_1 \\in \\mathbb{R}^{batch_size \\times 1}$, $b_1 \\in \\mathbb{R}^{batch_size}$, $W_2 \\in \\mathbb{R}^{1 \\times batch_size}$, $b_2 \\in \\mathbb{R}$. En este caso codificaremos, los parámetros del sistema en un vector de $\\mathbb{R}^{3N + 1}$ dado por\n",
        "\n",
        "$$ \\theta = (W_1, b_1, W_2, b_2)^T $$\n",
        "\n",
        "Esto no es lo que hacen las librerías de aprendizaje profundo en la realidad, pero en este caso permite simplificar mucho los manejos de estructuras de datos utilizadas.\n",
        "\n",
        "Para lo que sigue utilizaremos la librería ``autograd`` (instalada ya en Google Colab) que facilitará implementar la diferenciación automática (utilizada en las librerías más importantes de *deep learning*) para calcular facilmente el gradiente de la función de pérdida. Esta librería sobrescribe la librería ``numpy`` por lo que ahora utilizaremos esa librería con el sobrenombre ``np`` como si fuese la librería original."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "UDxkpYSSdGy9"
      },
      "outputs": [],
      "source": [
        "# Numpy de autograd\n",
        "import autograd.numpy as np\n",
        "\n",
        "# Función de gradiente mediante diferenciación automática\n",
        "from autograd import grad\n",
        "\n",
        "# Permite utilizar isinstance y tuple en autograd\n",
        "from autograd.builtins import isinstance, tuple\n",
        "\n",
        "# Para graficar\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Fijamos la semilla\n",
        "np.random.seed(115)\n",
        "\n",
        "# Módulo para anotar funciones\n",
        "from typing import Union\n",
        "\n",
        "# Para hacer DataFrames\n",
        "import pandas as pd\n",
        "\n",
        "# Notas:\n",
        "# Documentación de autograd: https://github.com/HIPS/autograd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCmed-4lboo_"
      },
      "source": [
        "Buscaremos ajustar la red neuronal a datos *sampleados* desde una función $\\text{cos}(x)$ con cierto ruido gaussiano. Generemos los datos antes de empezar el ejercicio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "9SVDXCeyJLcF"
      },
      "outputs": [],
      "source": [
        "# Función a aproximar\n",
        "def f_true(x):\n",
        "    return np.cos(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "e5XJWDWkcFvk"
      },
      "outputs": [],
      "source": [
        "xdim = 1  # Dimensión de input\n",
        "Ndata = 20  # Cantidad de datos a samplear\n",
        "ydim = 1  # Dimensión de output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "HeC4Z01ZjlJE",
        "outputId": "91b79880-7c9a-4d78-946c-c1a02e51eedb"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Datos aleatorios\n",
        "x_train = np.random.random((xdim, Ndata))\n",
        "\n",
        "# Sampleo de datos\n",
        "desv = 3e-2\n",
        "y_train = f_true(x_train) + desv * np.random.randn(*x_train.shape)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(x_train.flatten(), f_true(x_train).flatten(), label=\"Original\")\n",
        "plt.scatter(x_train.flatten(), y_train.flatten(), label=\"Ruidosa\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.title(\"Datos de entrenamiento con y sin ruido\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhYCbiTfNHdP"
      },
      "source": [
        "#### **Ejercicio 1.1: Creación de una red neuronal de 1 capa oculta**\n",
        "\n",
        "Cree una función en Python ``net(params, x)`` que dados los parámetros codificados en un arreglo de ``numpy`` tal como se mostró arriba y un conjunto de datos $x \\in \\mathbb{R}^{1 \\times N_{data}}$ calcule el output de la red. Pruebe su función con parámetros inicializados aleatoriamente desde una uniforme estándar y el arreglo ``x_train`` creado antes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### **Solución Ejercicio 1.1.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "8KOcCwUVcQ-3"
      },
      "outputs": [],
      "source": [
        "def net(params: np.array, x: np.array, sigma: callable = np.tanh) -> np.array:\n",
        "    \"\"\"\n",
        "    Realisación de la red neuronal a una capa oculta, de ancho batch_size=(params.shape[0] - 1)/3, con dimensión de entrada y salida 1.\n",
        "\n",
        "    En la capa de entrada, se aplica la función de activación tangente hiperbólica compuesta con la función afín\n",
        "    Wa*x + ba, donde Wa son los primeros batch_size parámetros de params y ba los siguientes batch_size.\n",
        "    De la segunda capa a la salida, se aplica la función afín Wb*x + bb (sin acivación), donde Wb son los siguientes batch_size parámetros\n",
        "    de params, después de haber asignado Wa y ba, y bb es el último parametro.\n",
        "\n",
        "    Se aplica esta red a cada dato de x.\n",
        "\n",
        "    Args:\n",
        "        params (np.array): Parámetros de la red neuronal.\n",
        "        x (np.array): Datos de entrada de la red neuronal.\n",
        "\n",
        "    Returns:\n",
        "        np.array: Datos de salida de la red neuronal.\n",
        "\n",
        "    Raises:\n",
        "        AssertionError: Si params no es un np.array.\n",
        "        AssertionError: Si x no es un np.array.\n",
        "        AssertionError: Si el número de parámetros no es correcto.\n",
        "        AssertionError: Si la dimensión de x no es correcta.\n",
        "    \"\"\"\n",
        "\n",
        "    assert isinstance(params, np.ndarray), \"params debe ser un np.array.\"\n",
        "    assert isinstance(x, np.ndarray), \"x debe ser un np.array.\"\n",
        "    assert params.shape[0] % 3 == 1, \"El número de parámetros no es correcto.\"\n",
        "    assert x.ndim == 1 or (\n",
        "        x.ndim == 2 and 1 in x.shape\n",
        "    ), \"La dimensión de x no es correcta.\"\n",
        "\n",
        "    shape = x.shape\n",
        "    x = np.squeeze(x)\n",
        "    params = np.squeeze(params)\n",
        "\n",
        "    batch_size = int((params.shape[0] - 1) / 3)\n",
        "    Wa = params[:batch_size]\n",
        "    ba = params[batch_size : 2 * batch_size]\n",
        "    Wb = params[2 * batch_size : 3 * batch_size]\n",
        "    bb = params[3 * batch_size]\n",
        "\n",
        "    def single_data_case(x: float) -> float:\n",
        "        x = sigma(Wa * x + ba)\n",
        "        x = Wb @ x + bb\n",
        "        return x\n",
        "\n",
        "    y = np.array([single_data_case(xi) for xi in x]).reshape(shape)\n",
        "\n",
        "    return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ancho = 30  # Ancho de la red neuronal\n",
        "\n",
        "# Creamos un array de parámetros aleatorios mediante una uniforme estandard\n",
        "params = np.random.uniform(-1, 1, size=(3 * ancho + 1))\n",
        "\n",
        "y = net(params, x_train)\n",
        "\n",
        "# Creamos el plto\n",
        "plt.scatter(x_train, y)\n",
        "\n",
        "# Agregamos labels\n",
        "plt.xlabel(\"x_train\")\n",
        "plt.ylabel(\"net(params, x_train)\")\n",
        "plt.title(\"Gráfco de la red neuronal con parámetros aleatorios\")\n",
        "\n",
        "# Mostramos el plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ctGquuJezf-"
      },
      "source": [
        "#### **Ejercicio 1.2: Creación de la función de pérdida por *batches***\n",
        "\n",
        "La naturaleza estocástica del algoritmo proviene de que no se le entregan todos los datos de entrenamiento, sino que una muestra diferente en cada iteración de entrenamiento, dichas muestras las denotaremos *batches*. Implemente una función en Python ``loss(params)`` que dados unos parámetros ``params`` $\\theta$ haga lo siguiente:\n",
        "\n",
        "* Obtenga un subarreglo de tamaño $(1, N_{batches})$ de ``x_train`` de manera aleatoria y sin sustitución, digamos ``x_batch``.\n",
        "* Obtenga el ``y_batch`` correspondiente.\n",
        "* Calcule la pérdida cuadrática en este *batch*:\n",
        "\n",
        "$$ L(\\theta) = \\sum_{i=1}^{N_{batch}} (y_i - \\Phi_\\theta (x_i)) $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### **Solución Ejercicio 1.2.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "8HG1i-j0np1V"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "12.75526432285979"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def loss(\n",
        "    params: np.array, x: np.array = x_train, y: np.array = y_train, batch_size: int = Ndata\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Función que toma un np.array de parametros para la red neuronal, y un np.array de datos x e y, y calcula el error cuadrático medio\n",
        "    de la red neuronal con los datos x e y, utilizando un batch de tamaño batch_size.\n",
        "\n",
        "    Args:\n",
        "        params (np.array): Parámetros de la red neuronal.\n",
        "        x (np.array, optional): Datos de entrada de la red neuronal. Defaults to x_train.\n",
        "        y (np.array, optional): Datos de salida de la red neuronal. Defaults to y_train.\n",
        "        batch_size (int, optional): Tamaño del batch. Defaults to Nbatch.\n",
        "\n",
        "    returns:\n",
        "        float: Error cuadrático medio de la red neuronal con los datos x e y.\n",
        "\n",
        "    Raises:\n",
        "        AssertionError: Si params no es un np.array.\n",
        "        AssertionError: Si x no es un np.array.\n",
        "        AssertionError: Si y no es un np.array.\n",
        "        AssertionError: Si batch_size no es un entero.\n",
        "        AssertionError: Si el número de parámetros no es correcto.\n",
        "        AssertionError: Si la dimensión de x no es correcta.\n",
        "        AssertionError: Si las dimensiones de x e y no son compatibles.\n",
        "        AssertionError: Si el tamaño del batch es muy grande.\n",
        "    \"\"\"\n",
        "\n",
        "    assert isinstance(params, np.ndarray), \"params debe ser un np.array.\"\n",
        "    assert isinstance(x, np.ndarray), \"x debe ser un np.array.\"\n",
        "    assert isinstance(y, np.ndarray), \"y debe ser un np.array.\"\n",
        "    assert isinstance(batch_size, int), \"batch_size debe ser un entero.\"\n",
        "\n",
        "    assert params.shape[0] % 3 == 1, \"El número de parámetros no es correcto.\"\n",
        "    assert x.ndim == 1 or (\n",
        "        x.ndim == 2 and 1 in x.shape\n",
        "    ), \"La dimensión de x no es correcta.\"\n",
        "    assert x.shape == y.shape, \"Las dimensiones de x e y no son compatibles.\"\n",
        "    assert batch_size <= np.squeeze(x).shape[0], \"El tamaño del batch es muy grande.\"\n",
        "\n",
        "    x = np.squeeze(x)\n",
        "    y = np.squeeze(y)\n",
        "\n",
        "    # Elejimos un batch aleatorio con probabilidad uniforme sobre x, sin substitucion\n",
        "    indices = np.random.choice(len(x), size=batch_size, replace=False)\n",
        "    x_batch = x[indices]\n",
        "\n",
        "    # Obtenemos el y_batch correspondiente\n",
        "    y_batch = net(params, x_batch)\n",
        "\n",
        "    # Calculamos la perdida en el batch\n",
        "    MSE = np.mean((y[indices] - y_batch) ** 2)\n",
        "\n",
        "    return MSE\n",
        "\n",
        "\n",
        "loss(params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vx7Xx_d4hKLR"
      },
      "source": [
        "#### **Ejercicio 1.3: Cálculo del gradiente vía autodiferenciación y comparación con diferencias finitas**\n",
        "\n",
        "Con la función ``grad`` de ``autograd`` calcule el gradiente de la función de pérdida antes creada, con tamaño de *batch* igual a ``Ndata``, es decir, la función de pérdida se vuelve determinista en este caso (ya que le pasamos todos los datos al tomar los batches sin sustitución. Compare en norma este gradiente con el cálculado mediante por diferencias finitas centradas\n",
        "\n",
        "$$ \\frac{\\partial L}{ \\partial \\theta_j} (\\theta) \\approx \\frac{L(\\theta + \\varepsilon e_j) - L(\\theta - \\varepsilon e_j)}{2 \\varepsilon} $$\n",
        "\n",
        "Para $\\varepsilon \\in \\{ 10, 1, 0.1, 0.01 \\}$, evaluado los gradientes en los mismo parámetros utilizados en la parte anterior."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### **Solución Ejercicio 1.3.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para esta sección, usaremos un batch size igual a la cantidad de datos de entrenamiento, es decir, estos resultados son de caracter determinista en cuanto a la función de error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "kgzhW_ZMiY51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valores del gradiente de la loss function mediente diferencias finitas para eps en [10, 1, 0.1, 0.01]:\n",
            "\n",
            "eps = 10:\n",
            "[-2.11403906e-01 -1.56876747e-01 -1.37890194e-01  2.06402201e-01\n",
            " -1.51640013e-01  6.68360947e-03 -3.01980179e-01 -5.73401625e-01\n",
            " -1.85401336e-01  2.86460612e-01 -4.19082276e-01  3.06469550e-01\n",
            "  6.99554472e-01 -2.84935204e-01 -2.38612181e-01  2.06855949e-01\n",
            "  4.49956242e-01  3.34165911e-01  3.52257663e-01  6.19646775e-01\n",
            "  1.84515642e-01 -2.39811711e-01 -1.09390818e-01  1.94130046e-01\n",
            "  3.20062969e-01  3.69472397e-01 -6.99637712e-01 -4.56167617e-01\n",
            " -4.60324414e-01  4.40246638e-01 -2.20144148e-01 -1.62068752e-01\n",
            " -1.44773938e-01  2.12850002e-01 -1.57359148e-01  6.89069636e-03\n",
            " -3.24657705e-01 -5.93592090e-01 -1.95666967e-01  2.95412701e-01\n",
            " -4.37074144e-01  3.17879307e-01  7.22039583e-01 -2.94332131e-01\n",
            " -2.45945073e-01  2.13778541e-01  4.78378889e-01  3.45614961e-01\n",
            "  3.85844843e-01  6.45769766e-01  1.93603824e-01 -2.53999639e-01\n",
            " -1.13337040e-01  2.06338758e-01  3.31493922e-01  3.89815456e-01\n",
            " -7.36542778e-01 -4.78827329e-01 -4.82857130e-01  4.57024465e-01\n",
            " -4.22677538e+00  1.00106356e+00 -3.29401832e+00 -2.83804271e+00\n",
            "  3.39981186e-01  3.70766230e-01  6.09572269e+00  4.04734839e+00\n",
            "  4.22017238e+00 -2.04210626e+00  2.85079399e+00 -1.91649815e+00\n",
            "  2.76006430e+00  5.66834781e-01  1.33580677e+00 -6.05600020e-01\n",
            " -5.80124389e+00 -1.62485274e+00  6.24988311e+00  1.24589311e+00\n",
            " -4.47256390e+00  5.21073019e+00 -3.79926078e-01  2.46028113e+00\n",
            " -3.13384040e+00  2.36110314e+00 -3.18943734e+00  4.65154028e+00\n",
            "  5.39213177e+00  5.00810209e-01 -7.13308940e+00]\n",
            "\n",
            "eps = 1:\n",
            "[-0.66739477 -0.70815717 -0.56048977  0.83000192 -0.68958228  0.03128125\n",
            " -0.52697182 -2.30363563 -0.7027511   1.2492811  -1.92125389  1.43530914\n",
            "  2.66876803 -1.34528197 -1.09655119  0.97589226  1.08429536  1.57829311\n",
            "  0.40910792  2.79888041  0.64109006 -0.69383645 -0.51064925  0.84773435\n",
            "  1.36850161  1.5991288  -2.7060602  -1.69025147 -1.26418557  2.04209831\n",
            " -1.30668126 -1.20210316 -0.97419504  1.49009081 -1.16196868  0.05208331\n",
            " -1.24817046 -4.11613239 -1.2432923   2.16414874 -3.15228089  2.35801034\n",
            "  4.82299285 -2.21033834 -1.84826778  1.60717039  2.29839219  2.59241753\n",
            "  1.09314268  4.72981733  1.19138261 -1.37130362 -0.8491845   1.41185547\n",
            "  2.36365182  2.70763136 -4.81409107 -3.04085332 -2.62120249  3.41937627\n",
            " -4.22677538  1.00106356 -3.29401832 -2.83804271  0.33998119  0.37076623\n",
            "  6.09572269  4.04734839  4.22017238 -2.04210626  2.85079399 -1.91649815\n",
            "  2.7600643   0.56683478  1.33580677 -0.60560002 -5.80124389 -1.62485274\n",
            "  6.24988311  1.24589311 -4.4725639   5.21073019 -0.37992608  2.46028113\n",
            " -3.1338404   2.36110314 -3.18943734  4.65154028  5.39213177  0.50081021\n",
            " -7.1330894 ]\n",
            "\n",
            "eps = 0.1:\n",
            "[-0.63844571 -0.78454511 -0.60642934  0.86318987 -0.77007225  0.03559186\n",
            " -0.44927422 -2.40830439 -0.73613638  1.35600363 -2.1966735   1.65064788\n",
            "  2.70198307 -1.53321435 -1.23340651  1.11566823  0.96882102  1.81763439\n",
            "  0.33732997  3.19564042  0.64027169 -0.65214407 -0.58399094  0.96405066\n",
            "  1.48973994  1.80521596 -2.85721402 -1.73332672 -1.16311275  2.34782569\n",
            " -1.33853293 -1.52236651 -1.10388858  1.77874261 -1.46361622  0.06748143\n",
            " -0.995461   -4.74653099 -1.33095495  2.70315761 -3.86104731  2.98524292\n",
            "  5.45164836 -2.8399146  -2.37700463  2.0681556   1.99303451  3.32524917\n",
            "  0.79554398  5.89428194  1.23638052 -1.28640144 -1.08851006  1.6627101\n",
            "  2.84157543  3.20128637 -5.26278382 -3.21183498 -2.48096503  4.37557896\n",
            " -4.22677538  1.00106356 -3.29401832 -2.83804271  0.33998119  0.37076623\n",
            "  6.09572269  4.04734839  4.22017238 -2.04210626  2.85079399 -1.91649815\n",
            "  2.7600643   0.56683478  1.33580677 -0.60560002 -5.80124389 -1.62485274\n",
            "  6.24988311  1.24589311 -4.4725639   5.21073019 -0.37992608  2.46028113\n",
            " -3.1338404   2.36110314 -3.18943734  4.65154028  5.39213177  0.50081021\n",
            " -7.1330894 ]\n",
            "\n",
            "eps = 0.01:\n",
            "[-0.6379796  -0.78537463 -0.60690124  0.86339314 -0.77097018  0.03564369\n",
            " -0.44844265 -2.40896903 -0.73638671  1.35706    -2.20009959  1.65334493\n",
            "  2.70167956 -1.53546591 -1.23499267  1.11736541  0.96740593  1.82063558\n",
            "  0.33662099  3.2005773   0.64010196 -0.65152346 -0.58488613  0.9654939\n",
            "  1.49098461  1.80773302 -2.85845151 -1.73340508 -1.16178107  2.35165024\n",
            " -1.33807124 -1.52656272 -1.10499474  1.78207838 -1.46752344  0.06769245\n",
            " -0.9921198  -4.75215524 -1.33118419  2.7100339  -3.86964665  2.99345028\n",
            "  5.4571148  -2.84839623 -2.38414278  2.07438847  1.98802752  3.33508413\n",
            "  0.79214927  5.90894851  1.23604232 -1.28437289 -1.09172381  1.66559083\n",
            "  2.84691085  3.20678173 -5.26499274 -3.21157083 -2.47743268  4.38837825\n",
            " -4.22677538  1.00106356 -3.29401832 -2.83804271  0.33998119  0.37076623\n",
            "  6.09572269  4.04734839  4.22017238 -2.04210626  2.85079399 -1.91649815\n",
            "  2.7600643   0.56683478  1.33580677 -0.60560002 -5.80124389 -1.62485274\n",
            "  6.24988311  1.24589311 -4.4725639   5.21073019 -0.37992608  2.46028113\n",
            " -3.1338404   2.36110314 -3.18943734  4.65154028  5.39213177  0.50081021\n",
            " -7.1330894 ]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Cálculo de gradiente mediante diferencias finitas\n",
        "def finite_diff_grad(params: np.array, eps: Union[int,float] = 1e-2) -> np.array:\n",
        "    \"\"\"\n",
        "    Función que toma un np.array de parametros para la red neuronal, y calcula el gradiente de la función de perdida\n",
        "    con respecto a los parametros mediante diferencias finitas.\n",
        "\n",
        "    Args:\n",
        "        params (np.array): Parámetros de la red neuronal.\n",
        "        eps (float, optional): Tamaño del paso para las diferencias finitas. Defaults to 1e-2.\n",
        "\n",
        "    Returns:\n",
        "        np.array: Gradiente de la función de perdida con respecto a los parametros evaluada en params.\n",
        "\n",
        "    Raises:\n",
        "        AssertionError: Si params no es un np.array.\n",
        "        AssertionError: Si eps no es un flotante.\n",
        "    \"\"\"\n",
        "\n",
        "    assert isinstance(params, np.ndarray), \"params debe ser un np.array.\"\n",
        "    assert isinstance(eps, (int,float)), \"eps debe ser un flotante.\"\n",
        "\n",
        "    grad = np.zeros(params.shape)\n",
        "\n",
        "    for i in range(len(params)):\n",
        "        params[i] += eps\n",
        "        loss_plus = loss(params)\n",
        "        params[i] -= 2 * eps\n",
        "        loss_minus = loss(params)\n",
        "        params[i] += eps\n",
        "        grad[i] = (loss_plus - loss_minus) / (2 * eps)\n",
        "\n",
        "    return grad\n",
        "\n",
        "eps = [10,1,0.1,0.01]\n",
        "\n",
        "print(f\"Valores del gradiente de la loss function mediente diferencias finitas para eps en {eps}:\")\n",
        "print()\n",
        "finite_gradients = []\n",
        "for e in eps:\n",
        "    print(f\"eps = {e}:\")\n",
        "    gradient = (e, finite_diff_grad(params, e))\n",
        "    finite_gradients.append(gradient)\n",
        "    print(gradient[1])\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradiente de la función de pérdida mediante autograd:\n",
            "\n",
            "[-0.63797487 -0.78538301 -0.606906    0.86339518 -0.77097926  0.03564421\n",
            " -0.44843425 -2.40897568 -0.73638923  1.35707066 -2.20013428  1.65337225\n",
            "  2.70167641 -1.5354887  -1.23500872  1.11738259  0.96739161  1.82066597\n",
            "  0.33661383  3.20062729  0.64010022 -0.65151717 -0.58489519  0.96550851\n",
            "  1.49099718  1.8077585  -2.85846396 -1.73340582 -1.16176759  2.35168898\n",
            " -1.33806646 -1.52660524 -1.10500586  1.78211212 -1.46756302  0.06769459\n",
            " -0.99208597 -4.75221185 -1.3311864   2.71010354 -3.86973368  2.99353344\n",
            "  5.45716982 -2.84848219 -2.38421513  2.07445165  1.98797673  3.33518381\n",
            "  0.79211495  5.90909702  1.23603878 -1.28435225 -1.09175639  1.66561997\n",
            "  2.84696476  3.20683727 -5.26501463 -3.21156785 -2.47739673  4.38850797\n",
            " -4.22677538  1.00106356 -3.29401832 -2.83804271  0.33998119  0.37076623\n",
            "  6.09572269  4.04734839  4.22017238 -2.04210626  2.85079399 -1.91649815\n",
            "  2.7600643   0.56683478  1.33580677 -0.60560002 -5.80124389 -1.62485274\n",
            "  6.24988311  1.24589311 -4.4725639   5.21073019 -0.37992608  2.46028113\n",
            " -3.1338404   2.36110314 -3.18943734  4.65154028  5.39213177  0.50081021\n",
            " -7.1330894 ]\n"
          ]
        }
      ],
      "source": [
        "# Calculamos el gradiente mediante grad de autograd\n",
        "grad_loss = grad(loss)\n",
        "\n",
        "print(\"Gradiente de la función de pérdida mediante autograd:\")\n",
        "print()\n",
        "auto_gradient = grad_loss(params)\n",
        "print(auto_gradient)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Comparamos los resultados del gradiente mediente autograd y diferencias finitas para cada $\\varepsilon$ especificado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  eps  gradient error\n",
            "10.00       15.428508\n",
            " 1.00        2.819216\n",
            " 0.10        0.034679\n",
            " 0.01        0.000348\n"
          ]
        }
      ],
      "source": [
        "gradient_error = []\n",
        "\n",
        "for e, finite_gradient in finite_gradients:\n",
        "    error = np.linalg.norm(auto_gradient - finite_gradient)\n",
        "    gradient_error.append((e, error))\n",
        "\n",
        "gradient_error_df = pd.DataFrame(gradient_error, columns=[\"eps\", \"gradient error\"])\n",
        "\n",
        "print(gradient_error_df.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksm7JUDDhAfT"
      },
      "source": [
        "#### **Ejercicio 1.4: Implementación de Adam**\n",
        "\n",
        "Vuelva a calcular el gradiente de la función de pérdida, pero ahora utilizando un tamaño de batch de $5$ (ahora sí se vuelve aleatoria la función de pérdida). Utilice 10000 iteraciones para el algoritmo y los mismos parámetros $\\alpha, \\beta_1, \\beta_2, \\varepsilon$ del artículo original. Grafique la evolución de la función de pérdida a través de las iteraciones en escala log-log (escala logarítmica en ambos ejes) y el resultado de la red en contraste con los datos y la función sin ruido evaluada en los puntos de entrenamiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### **Solución Ejercicio 1.4.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "iiKLJuifxE_X"
      },
      "outputs": [],
      "source": [
        "def ADAM(\n",
        "    param0: np.array,\n",
        "    f: callable,\n",
        "    alpha: float = 0.001,\n",
        "    beta1: float = 0.9,\n",
        "    beta2: float = 0.999,\n",
        "    eps: float = 1e-8,\n",
        "    max_iter: int = 1000,\n",
        "    min_error=5e-5,\n",
        ") -> np.array:\n",
        "    \"\"\"\n",
        "    Función que recibe un np.array de parametros iniciales, una función de costo, y los hiperparámetros alpha, beta1, beta2 y eps\n",
        "    para el optimizador ADAM, y retorna un np.array de parámetros optimizados para la función de costo f.\n",
        "\n",
        "    Args:\n",
        "        param0 (np.array): Parámetros iniciales.\n",
        "        f (callable): Función de costo estocástica.\n",
        "        alpha (float, optional): Cota superior para los pasos. Defaults to 0.001.\n",
        "        beta1 (float, optional): Taza de decaimiento exponencial para el promedio de los gradientes. Defaults to 0.9.\n",
        "        beta2 (float, optional): Taza de decaimiento exponencial para el promedio de los gradientes al cuadrado. Defaults to 0.999.\n",
        "        eps (float, optional): Término de regularización. Defaults to 1e-8.\n",
        "\n",
        "    Returns:\n",
        "        np.array: Parámetros optimizados para la función de costo f.\n",
        "    \"\"\"\n",
        "\n",
        "    m = [np.zeros_like(param0)]  # Inicializamos el primer momento estimado\n",
        "    v = [np.zeros_like(param0)]  # Inicializamos el segundo momento estimado\n",
        "    t = [0]  # Inicializamos el contador de pasos\n",
        "\n",
        "    g = [None]\n",
        "    m_hat = [None]\n",
        "    v_hat = [None]\n",
        "\n",
        "    params = [param0]\n",
        "\n",
        "    stochastic_error = [f(params[-1])]\n",
        "\n",
        "    while t[-1] < max_iter and f(params[-1]) > min_error:\n",
        "        t.append(t[-1] + 1)\n",
        "        g.append(\n",
        "            grad(f)(params[-1])\n",
        "        )  # Obtener gradiente c.r. al objetivo estocástico\n",
        "        m.append(\n",
        "            beta1 * m[-1] + (1 - beta1) * g[-1]\n",
        "        )  # Actualizamos el primer momento estimado sesgado\n",
        "        v.append(\n",
        "            beta2 * v[-1] + (1 - beta2) * g[-1] ** 2\n",
        "        )  # Actualizamos el segundo momento estimado sesgado\n",
        "        m_hat.append(\n",
        "            m[-1] / (1 - beta1 ** t[-1])\n",
        "        )  # Calculamos el primer momento estimado corregido\n",
        "        v_hat.append(\n",
        "            v[-1] / (1 - beta2 ** t[-1])\n",
        "        )  # Calculamos el segundo momento estimado corregido\n",
        "        params.append(\n",
        "            params[-1] - alpha * m_hat[-1] / (np.sqrt(v_hat[-1]) + eps)\n",
        "        )  # Actualizamos los parámetros\n",
        "        stochastic_error.append(f(params[-1]))\n",
        "        print(f(params[-1]))\n",
        "\n",
        "    return params[-1]  # Parametro resultante"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12.236279749053887\n",
            "11.93283818206502\n",
            "13.021544593043913\n",
            "11.90273478708761\n",
            "12.070756470889156\n",
            "11.356018053211747\n",
            "11.048860061212435\n",
            "10.51329303193032\n",
            "10.171927166010034\n",
            "10.440058963156218\n",
            "9.942049685112016\n",
            "10.429557375580528\n",
            "9.442479640139158\n",
            "10.259729013766695\n",
            "10.262603620241977\n",
            "9.246008734309374\n",
            "10.045307014229177\n",
            "9.460795360697777\n",
            "9.632037680057504\n",
            "9.488899892597294\n",
            "9.179911538941111\n",
            "8.982397274355627\n",
            "8.773172535258855\n",
            "8.76583916280764\n",
            "8.087692654573182\n",
            "8.609817848606806\n",
            "7.878564053723868\n",
            "7.119822178554848\n",
            "7.550399250268448\n",
            "7.0125143686524165\n",
            "7.073706762193622\n",
            "7.5557070493540675\n",
            "6.779520710115219\n",
            "6.658130479260437\n",
            "6.659367577241893\n",
            "6.200979082871584\n",
            "6.3619500189408615\n",
            "6.547500111014917\n",
            "6.52264630479749\n",
            "5.61766749470228\n",
            "5.715735292892452\n",
            "5.900020731406614\n",
            "5.876663058733974\n",
            "5.587660131571407\n",
            "5.648446891809004\n",
            "5.483901963244487\n",
            "5.507302358330726\n",
            "5.395761528614431\n",
            "5.223143909868147\n",
            "4.909298156918868\n",
            "4.995086747926651\n",
            "4.832642067138822\n",
            "4.643680209909952\n",
            "4.473099269574372\n",
            "4.562386341110479\n",
            "4.396750700580055\n",
            "4.290162610265933\n",
            "4.171685926195289\n",
            "3.906959427569592\n",
            "4.108399197178319\n",
            "3.9375730973361187\n",
            "3.667182282865241\n",
            "3.867646077562351\n",
            "3.692575402183034\n",
            "3.4708568320372697\n",
            "3.5608324369033255\n",
            "3.393067661164861\n",
            "3.34508995013053\n",
            "3.2510488279477228\n",
            "3.271095002748089\n",
            "3.079523647787787\n",
            "3.0087219613241465\n",
            "2.9830048456452203\n",
            "2.8090003998321214\n",
            "2.8079659522263523\n",
            "2.724771354330009\n",
            "2.6498767679914734\n",
            "2.664353706892069\n",
            "2.48791073767157\n",
            "2.5155427016235388\n",
            "2.4180626596915284\n",
            "2.3143978660381648\n",
            "2.3075013211226305\n",
            "2.212669978016182\n",
            "2.1415484860197544\n",
            "2.112158685822009\n",
            "2.102965474927389\n",
            "2.030429409571842\n",
            "1.9268701206982932\n",
            "1.8670287589864736\n",
            "1.8862227751215492\n",
            "1.827406307057969\n",
            "1.817609811205323\n",
            "1.7328788375489164\n",
            "1.673368017191961\n",
            "1.644988420036191\n",
            "1.5589533073842876\n",
            "1.5281436472748475\n",
            "1.4788693667494317\n",
            "1.483433219189126\n",
            "1.4280323547458487\n",
            "1.344998684910121\n",
            "1.3447208331568234\n",
            "1.3062783532350108\n",
            "1.2903853876953824\n",
            "1.2331761390968237\n",
            "1.1294165433636663\n",
            "1.1908398124509305\n",
            "1.1364648946785487\n",
            "1.1426940867592106\n",
            "1.098124146828085\n",
            "1.0303459718773005\n",
            "1.0198106044465434\n",
            "0.979796848359092\n",
            "0.9423552609634369\n",
            "0.9420580979099542\n",
            "0.9449388363858271\n",
            "0.8653239090813714\n",
            "0.8274187295122951\n",
            "0.8603797806328443\n",
            "0.8123885790496905\n",
            "0.7753885948408222\n",
            "0.7471645880106815\n",
            "0.7400047604354725\n",
            "0.6373938026177369\n",
            "0.733451376532751\n",
            "0.7166684979902602\n",
            "0.6517666351773257\n",
            "0.5787092836967185\n",
            "0.6041639363317997\n",
            "0.5702958735945787\n",
            "0.5769411689574357\n",
            "0.5389126972671672\n",
            "0.46671995794071675\n",
            "0.4516419509264038\n",
            "0.5155057280496175\n",
            "0.4672327379944747\n",
            "0.5046405238807845\n",
            "0.44062061437294175\n",
            "0.477911447874392\n",
            "0.3503481187100376\n",
            "0.42543986733934636\n",
            "0.4025409987095614\n",
            "0.4358653784333689\n",
            "0.3441513085893636\n",
            "0.4274110449582598\n",
            "0.390507603445238\n",
            "0.3474155121012096\n",
            "0.3400157833771288\n",
            "0.2793949351847521\n",
            "0.26772880349289396\n",
            "0.2793400602755919\n",
            "0.2659842942448085\n",
            "0.3137203542063407\n",
            "0.261839132274471\n",
            "0.24108209077947712\n",
            "0.21151128623498955\n",
            "0.2379557424477743\n",
            "0.21841833096066116\n",
            "0.2215209490378956\n",
            "0.24830872076581656\n",
            "0.17401720808714627\n",
            "0.18060379566757095\n",
            "0.18425210262602337\n",
            "0.15684988166099617\n",
            "0.1986943885771142\n",
            "0.1729897789824056\n",
            "0.16102836353674257\n",
            "0.17930661415874322\n",
            "0.1513085864377167\n",
            "0.10042536816685807\n",
            "0.12328456296953119\n",
            "0.14186233923877814\n",
            "0.08603351737776214\n",
            "0.12431994084179668\n",
            "0.15742791062878245\n",
            "0.08490704485892202\n",
            "0.1064438151240447\n",
            "0.08328874957790439\n",
            "0.12210082329324087\n",
            "0.111084081904351\n",
            "0.0844282822778202\n",
            "0.11790059578037841\n",
            "0.07238362696341352\n",
            "0.09920077988172328\n",
            "0.0981462367451934\n",
            "0.10403106193097311\n",
            "0.08969855469459803\n",
            "0.09047248019675921\n",
            "0.08276429426821619\n",
            "0.08583719373603002\n",
            "0.06255979254412974\n",
            "0.08991172904246247\n",
            "0.07663478782926948\n",
            "0.07860572926154424\n",
            "0.05574889167032469\n",
            "0.0455560687773896\n",
            "0.047435302862648125\n",
            "0.05530858003313619\n",
            "0.031338250775685896\n",
            "0.053135034249059986\n",
            "0.048075629876989656\n",
            "0.025407607607067572\n",
            "0.06668963264989825\n",
            "0.03337798947146499\n",
            "0.01574487331047195\n",
            "0.032074952795555334\n",
            "0.022423226626313776\n",
            "0.040128701376385745\n",
            "0.02469818963309283\n",
            "0.0345645027015067\n",
            "0.02170903986205875\n",
            "0.03417484332027304\n",
            "0.03277334259526586\n",
            "0.02526253362647406\n",
            "0.007873955863540111\n",
            "0.015790407851517804\n",
            "0.010668294310241227\n",
            "0.028470685080287973\n",
            "0.005298733644080964\n",
            "0.026236970948160597\n",
            "0.021486716017985227\n",
            "0.01844581541487427\n",
            "0.024039796623974968\n",
            "0.00278526829288715\n",
            "0.006746892710212599\n",
            "0.014058882368996167\n",
            "0.022938209661916616\n",
            "0.023234329400187367\n",
            "0.012871809818734231\n",
            "0.026546314554983536\n",
            "0.012772253704555276\n",
            "0.01994236929739911\n",
            "0.0059314798566773436\n",
            "0.02072641233340359\n",
            "0.009011079628216272\n",
            "0.011129814420950766\n",
            "0.010590124860529418\n",
            "0.01735232379660661\n",
            "0.01029636641895121\n",
            "0.013966896309917081\n",
            "0.00847676649200653\n",
            "0.007200167675224266\n",
            "0.015104095824689056\n",
            "0.007351989683362288\n",
            "0.00874207580640965\n",
            "0.022213229884927792\n",
            "0.018564039923031857\n",
            "0.007707787821943269\n",
            "0.008815703206731435\n",
            "0.01721887894797768\n",
            "0.022911474759572704\n",
            "0.008090522960211535\n",
            "0.010386045000475047\n",
            "0.005210027024950087\n",
            "0.02286010509453521\n",
            "0.00647674572084788\n",
            "0.005798751827170439\n",
            "0.01776863777123961\n",
            "0.021713148469187888\n",
            "0.0060287371710784615\n",
            "0.009227753462582445\n",
            "8.243828054847695e-05\n",
            "0.020596568832247968\n",
            "0.014281563129266123\n",
            "0.01021361711118947\n",
            "0.007486133371916616\n",
            "0.003617315815477161\n",
            "0.006700742857601419\n",
            "0.01196490445956064\n",
            "0.01448135239091095\n",
            "0.007455726262923226\n",
            "0.0070392189753336835\n",
            "0.009857862350709344\n",
            "0.0036398417055092795\n",
            "0.012959594792104909\n",
            "0.0066532607326626496\n",
            "0.015162890889583114\n",
            "0.0074249110870839505\n",
            "0.004226852820386595\n",
            "0.010775613624212744\n",
            "0.003614710117041177\n",
            "0.00540244312793575\n",
            "0.015383614624819552\n",
            "0.006355528928147875\n",
            "0.0031132835100266686\n",
            "0.003931169775976914\n",
            "0.009613444607867547\n",
            "0.01105187596131862\n",
            "0.0007507996322091561\n",
            "0.0020785108700340513\n",
            "0.005118905714227699\n",
            "0.006509278471875507\n",
            "0.004222831947831007\n",
            "0.013070199814751951\n",
            "0.009106487805386683\n",
            "0.00670095426330449\n",
            "0.005762652209953524\n",
            "0.012978541568240987\n",
            "0.00864895365833068\n",
            "0.004458220650584582\n",
            "0.008939919966386042\n",
            "0.004506402206405816\n",
            "0.000939191241277767\n",
            "0.006247878038757192\n",
            "0.004223818772476805\n",
            "0.010590266435745867\n",
            "0.009239273266839081\n",
            "0.0077993618699014194\n",
            "0.0031871636821387975\n",
            "0.0077702914012306055\n",
            "0.0012353223738201511\n",
            "0.007297047185456479\n",
            "0.0056611558097886035\n",
            "0.005792049249239166\n",
            "0.0022201082799520383\n",
            "0.007223319822467249\n",
            "0.006288008861975945\n",
            "0.005103872795276362\n",
            "0.0027472085856422024\n",
            "0.0031984247001350372\n",
            "0.003655471141437769\n",
            "0.0027859370497590186\n",
            "0.007937201476294722\n",
            "0.001834076616939304\n",
            "0.00803429806049096\n",
            "0.0036351681848822482\n",
            "0.0037396152619051616\n",
            "0.001244192720494719\n",
            "0.005881002310438074\n",
            "0.011066794809801616\n",
            "0.0016150394337427498\n",
            "0.001191724624292391\n",
            "0.0013281421990003243\n",
            "0.005156582677328351\n",
            "0.0044396375231800286\n",
            "0.00447961386114148\n",
            "0.00392951558812397\n",
            "0.001355849261726065\n",
            "0.0027627372310056663\n",
            "0.00504507677536202\n",
            "0.009587072800717371\n",
            "0.0043239773229499295\n",
            "0.004359700870171749\n",
            "0.005270425311724777\n",
            "0.002875789877388238\n",
            "0.0036101927973791305\n",
            "0.004145843461409524\n",
            "0.0061150237391152775\n",
            "0.0016052583588955015\n",
            "0.0068051874696052035\n",
            "0.00360052143413178\n",
            "0.0062357978852635165\n",
            "0.002710449623926566\n",
            "0.0063199099234897225\n",
            "0.0011488982091325292\n",
            "0.0020006422713844943\n",
            "0.0043981102740093024\n",
            "0.0027056428388918226\n",
            "0.0011122680951504934\n",
            "0.0031504628612251417\n",
            "0.00965793472542226\n",
            "0.0033820825045933894\n",
            "0.006388466918212973\n",
            "0.007070545171076347\n",
            "0.0068329483803122705\n",
            "0.0021495384029670997\n",
            "0.005947430987937973\n",
            "0.0009705451810361228\n",
            "0.0016987468632152802\n",
            "0.005425451586444328\n",
            "0.0017581716965212805\n",
            "0.005198577170755981\n",
            "0.004246441912041683\n",
            "0.004488572253743587\n",
            "0.002344609956034796\n",
            "0.0035444648417534237\n",
            "0.003924688308539237\n",
            "0.0046889036405814155\n",
            "0.001961080710801391\n",
            "0.0030496848541007255\n",
            "0.0024776783053120353\n",
            "0.002098566179557633\n",
            "0.001825465863308235\n",
            "0.007957350228675875\n",
            "0.003914783328642724\n",
            "0.0033534980411690065\n",
            "0.004530593194633848\n",
            "0.005498512769122299\n",
            "0.006499605648696819\n",
            "0.001489134716400948\n",
            "0.0023700910214659145\n",
            "0.001409117472202731\n",
            "0.0069192083822019745\n",
            "0.002371691092990745\n",
            "0.006437658244961944\n",
            "0.0037112715300193994\n",
            "0.0003262858721380439\n",
            "0.0022355857762854864\n",
            "0.0031827104481833993\n",
            "0.002894645765445349\n",
            "0.003814781466948379\n",
            "0.005091048364372803\n",
            "0.0021627007768225274\n",
            "0.003922064055869094\n",
            "0.00237162168048985\n",
            "0.0036305557829868296\n",
            "0.0020212388288335455\n",
            "0.002707837411619669\n",
            "0.00147982557489511\n",
            "0.0040660294325316464\n",
            "0.0023819123929421293\n",
            "0.0019332904478293563\n",
            "0.0018217218153969087\n",
            "0.003771777590021878\n",
            "0.0028422846038465913\n",
            "0.005180888559162252\n",
            "0.006697545997633203\n",
            "0.0018323815234688172\n",
            "0.0015352621554763578\n",
            "0.005362795235025544\n",
            "0.0022051705482704588\n",
            "0.0021934265986577723\n",
            "0.0032959644174493123\n",
            "0.005097975080304769\n",
            "0.0038287719185044547\n",
            "0.002024418208990638\n",
            "0.0033265481771233758\n",
            "0.0055890281373400155\n",
            "0.0034043395404159777\n",
            "0.0009749003041451338\n",
            "0.0012111595090423608\n",
            "0.0011260487146772633\n",
            "0.0010847655992937293\n",
            "0.0035584913901328674\n",
            "0.002113565856897223\n",
            "0.0015707239372449947\n",
            "0.0020028909734671205\n",
            "0.0009473251274253827\n",
            "0.004990008467316193\n",
            "0.001610362859182444\n",
            "0.00039422443974298095\n",
            "0.002447106121610118\n",
            "0.0019331474185825374\n",
            "0.00217622277512964\n",
            "0.0011049482374755758\n",
            "0.002023155394041371\n",
            "0.0032751775198285745\n",
            "0.00013912732185998678\n",
            "0.0023235881569455994\n",
            "0.0019017139155308462\n",
            "0.0018309059567535528\n",
            "0.005155887067873508\n",
            "0.005419690302259179\n",
            "0.002461115690078772\n",
            "0.0018069848959438753\n",
            "0.0010745089152733006\n",
            "0.0009808946934279285\n",
            "0.0017517115927849513\n",
            "0.0018573298694504793\n",
            "0.0031495999146405793\n",
            "0.0003729928608248996\n",
            "0.0020264527480476466\n",
            "0.00259352607235013\n",
            "0.003119551919216844\n",
            "0.0030975134000055097\n",
            "0.0027429971566125195\n",
            "0.001061318570695826\n",
            "0.0029880774287063825\n",
            "0.0036602009497257774\n",
            "0.00134377073988404\n",
            "0.002928180238447623\n",
            "0.0011745497316466478\n",
            "0.004764417412102451\n",
            "0.0013962690171896157\n",
            "0.0014315463199436307\n",
            "0.0016201464496614227\n",
            "0.0005245203406213055\n",
            "0.0037697807325697366\n",
            "0.00042431928961624113\n",
            "0.0029090366457453893\n",
            "0.002451595353005658\n",
            "0.0015287366558004493\n",
            "0.0025703260820202625\n",
            "0.0021887919323935155\n",
            "0.003084661770832311\n",
            "0.0010565490003631175\n",
            "0.0034750049347151086\n",
            "0.0017320833212604886\n",
            "0.0014985914577275267\n",
            "0.0012384033724875429\n",
            "0.0035815241703701733\n",
            "0.0038308072366182674\n",
            "0.0013703425576805934\n",
            "0.0034422466730097225\n",
            "0.000709397500396411\n",
            "0.0006830419645686168\n",
            "0.0014112595328864479\n",
            "0.0003836426636427874\n",
            "0.001834730656763273\n",
            "0.0017069038923081333\n",
            "0.0015147176744776374\n",
            "0.0025910372936385913\n",
            "0.0022153685799518323\n",
            "0.0022360373124080306\n",
            "0.0012119716157854808\n",
            "0.001964200737018014\n",
            "0.0028805278158679872\n",
            "0.0028176176822523784\n",
            "0.000596580068974409\n",
            "0.001492872740516291\n",
            "0.003223458756686543\n",
            "0.0006964874329042237\n",
            "0.0019487678539133455\n",
            "0.0007623567613184731\n",
            "0.002980041338463657\n",
            "0.0015515527042495644\n",
            "0.0003530607717416156\n",
            "0.0032628947805769387\n",
            "0.0009438785146499955\n",
            "0.0009593463344894583\n",
            "0.0023985317061183623\n",
            "0.0019066140830318642\n",
            "0.003501297291034264\n",
            "0.0013967832159272203\n",
            "0.0005836874273062986\n",
            "0.0009532751583849503\n",
            "0.0022225069969051435\n",
            "0.0020939671977678793\n",
            "0.0014607665445784922\n",
            "0.000725147553440944\n",
            "0.0002363709188229375\n",
            "0.0011693323724032024\n",
            "0.0009593600508521798\n",
            "0.001238061267566262\n",
            "0.0018143862577722914\n",
            "0.0018513822898574817\n",
            "0.0011416343035957968\n",
            "0.0026238999466319723\n",
            "0.0015977802245805174\n",
            "0.0010465407710527734\n",
            "0.0007788440721688581\n",
            "0.0010053899868351162\n",
            "0.000388005932340676\n",
            "0.0005399045237681415\n",
            "0.003216801468346117\n",
            "0.0005548047242059709\n",
            "0.0006599591272676654\n",
            "0.0015211689028701673\n",
            "0.0025167466429778912\n",
            "0.0016042362582280507\n",
            "0.0028197170129906704\n",
            "0.0029466309818341053\n",
            "0.0014318431747307177\n",
            "0.002031424103134112\n",
            "0.0006674553984333795\n",
            "0.0015340382362095215\n",
            "0.0007477733683402176\n",
            "0.0022195772298122416\n",
            "0.0023308720332935505\n",
            "0.0007208663466056635\n",
            "0.002040761386895229\n",
            "0.0012922670317827769\n",
            "0.0018361526913845676\n",
            "0.0009803915754608699\n",
            "0.0017827377408908833\n",
            "0.0016087422974071168\n",
            "0.0013632343795584828\n",
            "0.0016923717529464092\n",
            "0.001272641559954038\n",
            "0.0019426233068102964\n",
            "0.00037629599406683803\n",
            "0.0013517804611524527\n",
            "0.0008961081263444309\n",
            "0.001564741688521087\n",
            "0.0021683691726389785\n",
            "0.0024471944540447933\n",
            "0.0007773036835915395\n",
            "0.0023863539311368967\n",
            "0.001348760789286087\n",
            "0.0013166464829060965\n",
            "0.0004100138334212643\n",
            "0.0013414500550411749\n",
            "0.002049714842471605\n",
            "0.0017874517706317071\n",
            "0.0014440135935592856\n",
            "0.0002176952410026049\n",
            "0.0014404399467083085\n",
            "0.0012086004201610507\n",
            "0.0017107480840520008\n",
            "0.0014106310371592402\n",
            "0.000880053635935206\n",
            "0.0018080220719841312\n",
            "0.0008012106223409486\n",
            "0.00042835660093386817\n",
            "0.0007273907862519241\n",
            "0.0011019435557238803\n",
            "0.0006786353003766488\n",
            "0.0021312314807948457\n",
            "0.0022152676525548152\n",
            "0.0024412793856461593\n",
            "0.0005107469974029609\n",
            "0.0008486877608820656\n",
            "0.0010630076289763076\n",
            "0.00296350216214526\n",
            "0.0003825971339883856\n",
            "0.0015507027941712285\n",
            "0.001544942014073041\n",
            "0.0017448255018037851\n",
            "0.001547684962451978\n",
            "0.0012430383933890764\n",
            "0.000328049528951234\n",
            "0.0018996528727257254\n",
            "0.0006034731940244077\n",
            "0.00139974511967907\n",
            "0.0007175762324921656\n",
            "0.0013600458680589598\n",
            "0.0012537855146005227\n",
            "0.0006177585043545796\n",
            "0.0010756866695218908\n",
            "0.0008167423239728089\n",
            "0.001081327582679692\n",
            "0.0005571806078552747\n",
            "0.0010079306902206454\n",
            "0.0004941641258184913\n",
            "0.0004831171787105041\n",
            "0.0019726654701973227\n",
            "0.0007035903300083801\n",
            "0.0010509200484274828\n",
            "0.0009338513679344093\n",
            "0.0006234004459761666\n",
            "0.0018750831293434795\n",
            "0.000850600038492959\n",
            "0.001438476843483523\n",
            "0.001503569129721149\n",
            "0.0012252172702222222\n",
            "0.00037512943456280824\n",
            "0.0007838781317227176\n",
            "0.00170736410888833\n",
            "0.0006216319875608803\n",
            "0.0006299729690439874\n",
            "0.0012865707974251182\n",
            "0.0017476501326457185\n",
            "0.0012202858621848003\n",
            "0.0015149311970812248\n",
            "0.0007950300006935711\n",
            "0.0004163242821361329\n",
            "0.00027882326718659835\n",
            "0.0021205953304714786\n",
            "0.0017282526144845015\n",
            "0.0003598641819950397\n",
            "0.001008311266336781\n",
            "0.00012634963694189142\n",
            "0.0004869427403753894\n",
            "0.0011544818298318605\n",
            "0.000274043793748682\n",
            "0.0005309262109774384\n",
            "0.0002704933344062857\n",
            "0.0013758974308289884\n",
            "0.0016341415949517242\n",
            "0.0007109423211609876\n",
            "0.000962011426499663\n",
            "0.0012117156884865676\n",
            "0.0012742711221310162\n",
            "0.0012655237149450398\n",
            "0.0003006173788611348\n",
            "0.0005956202951245806\n",
            "0.0010954417955742967\n",
            "0.002126241451262908\n",
            "0.0020584785020299643\n",
            "0.001484778117751734\n",
            "0.001492363043798151\n",
            "0.00021775533498340492\n",
            "0.0005505789186586703\n",
            "0.0009048117948887059\n",
            "0.0019547016250810673\n",
            "0.0010141607187384668\n",
            "0.0002450571636198979\n",
            "0.0007632746181258004\n",
            "0.001521716285878977\n",
            "0.0009568609049032253\n",
            "0.0005134810134563162\n",
            "0.0008427896622495322\n",
            "0.000341577070957768\n",
            "0.0007329854731211595\n",
            "0.0010517145778181699\n",
            "0.0007663605729675484\n",
            "0.0007938791865318492\n",
            "0.0010915637234474643\n",
            "0.001155734049377537\n",
            "0.0004366427380753853\n",
            "0.001651158656079511\n",
            "0.0013432292788016953\n",
            "0.0003129763088411406\n",
            "0.0004228706526681481\n",
            "0.0015096311695729097\n",
            "0.00043324947780601407\n",
            "0.0018209276986545897\n",
            "0.0008164436577846081\n",
            "0.002065653078520211\n",
            "0.0004402688565543062\n",
            "0.001007635177331104\n",
            "0.0025486588261363747\n",
            "0.0005025038585098625\n",
            "0.0005202272340852481\n",
            "0.0007223718669854183\n",
            "0.001177681107921737\n",
            "0.0015210229197442358\n",
            "0.0006087795064589948\n",
            "0.0007863201522558825\n",
            "0.0015899628293591552\n",
            "0.001699603005366393\n",
            "0.0006085525934981143\n",
            "0.0009637674307554492\n",
            "0.0008463578140429943\n",
            "0.0005025290436782386\n",
            "0.0007866492839514908\n",
            "0.0015906159980468323\n",
            "0.0005619375872850934\n",
            "0.0009194690469112282\n",
            "0.0014222768937891474\n",
            "0.0006467860401548149\n",
            "0.0014904905250808088\n",
            "0.0007425706615453443\n",
            "0.0006185296530813261\n",
            "0.0004552247176217531\n",
            "0.0010825390089769604\n",
            "0.0007977239122096014\n",
            "0.0012491538704886087\n",
            "0.0010777998623394938\n",
            "0.0004714399603421791\n",
            "0.001040165450841026\n",
            "0.0009637571384039148\n",
            "0.0007118619376527438\n",
            "0.001398174765381674\n",
            "0.0009166981983405239\n",
            "0.0009007980512087501\n",
            "0.0013517261876799258\n",
            "0.00026991445731482523\n",
            "0.0004108166410056788\n",
            "0.0005470268470580923\n",
            "0.0016508447634322888\n",
            "0.001290538859928913\n",
            "0.0005776947329128801\n",
            "0.0009914109747217576\n",
            "0.0005819198248492325\n",
            "0.0006200025445506806\n",
            "0.0007640066591723306\n",
            "0.0008801292587172377\n",
            "0.001006978110810747\n",
            "0.0016924863130705005\n",
            "0.0009658140203389705\n",
            "0.0019237731950647904\n",
            "0.0006248821212943376\n",
            "0.0010883775297996687\n",
            "0.00046736225421778753\n",
            "0.0013108037214313722\n",
            "0.0014497927269070967\n",
            "0.001057216570284312\n",
            "0.00023050278780805373\n",
            "0.0011956746982674678\n",
            "0.0010043046804889984\n",
            "0.0003146945376452708\n",
            "0.0005037576481942587\n",
            "0.0010024019325365903\n",
            "0.0010539287453563877\n",
            "0.0005762669648470929\n",
            "0.0008284575141017155\n",
            "0.001516237681146543\n",
            "0.001216850728094985\n",
            "0.0009720079343753313\n",
            "0.0015367420788025888\n",
            "0.0005663578788608837\n",
            "0.0006899605002046391\n",
            "0.0003725281526198379\n",
            "0.0012238656941542022\n",
            "0.0005829546019705254\n",
            "0.00024738996687292774\n",
            "0.0014039978697411983\n",
            "0.001319280649156021\n",
            "0.0006266241830101884\n",
            "0.0006388289444581624\n",
            "0.0001382740244476057\n",
            "0.0003626992974232829\n",
            "0.0006080114836537841\n",
            "0.000966756339816012\n",
            "0.0004913525105621602\n",
            "0.0007128940831267866\n",
            "0.0010158191886396576\n",
            "0.00040246961667589256\n",
            "0.0005275591273458276\n",
            "0.0009158783483017516\n",
            "0.0014061566391990652\n",
            "0.0001881131828648952\n",
            "0.0011837436423422355\n",
            "0.000379209708031561\n",
            "0.0007530842601483308\n",
            "0.000816662787823327\n",
            "0.0009334933427478825\n",
            "0.00019380196681888025\n",
            "0.000956692061625163\n",
            "0.001155367453580592\n",
            "0.0008424325997981525\n",
            "0.0017613133262250793\n",
            "0.00041422576769582645\n",
            "0.0013418164806691807\n",
            "0.0007934290619847348\n",
            "0.00023985388100978712\n",
            "0.0014305900612308052\n",
            "0.0013048496593138844\n",
            "0.0011587776395441157\n",
            "0.0006660455632240915\n",
            "0.0006104581249302562\n",
            "0.00024476361949835664\n",
            "0.0013043520922231314\n",
            "0.0010430384684036423\n",
            "0.0009550555764126131\n",
            "0.0015115465232309585\n",
            "0.0014996206153624942\n",
            "0.0008676466797500612\n",
            "0.00015758617971215974\n",
            "0.0006178116466880287\n",
            "0.0007333603008483111\n",
            "0.0008212960335114889\n",
            "0.0009802177517958326\n",
            "0.0012294858932131842\n",
            "0.0014587081779276864\n",
            "0.0004539765169681321\n",
            "0.0018670414623886394\n",
            "0.0002771449870955954\n",
            "7.161521118248678e-05\n",
            "0.0006208133151843502\n",
            "0.0010826302877633008\n",
            "0.0003020827272283945\n",
            "0.0003716800994069614\n",
            "0.0004017637952197251\n",
            "0.0006892815114305131\n",
            "0.0008312318904270552\n",
            "0.0011656706962563635\n",
            "0.0003276158942993099\n",
            "0.001991310472737809\n",
            "0.0014410542029871611\n",
            "0.0005512044338953485\n",
            "0.0008269774588938854\n",
            "0.0011702710220842624\n",
            "0.0010380584848124028\n",
            "0.0007625518866706709\n",
            "0.0013769756768702258\n",
            "0.0009920854419763567\n",
            "0.0020090873640061973\n",
            "0.000949075028755212\n",
            "0.0009294561197853501\n",
            "0.001314798602013793\n",
            "0.0010433735853692635\n",
            "0.0009542734602818233\n",
            "0.0008166127663188349\n",
            "0.00024202828080324107\n",
            "0.0011126721251628283\n",
            "0.000647443259003838\n",
            "0.0002308019056810918\n",
            "0.0006025198567476402\n",
            "0.0012630435840534332\n",
            "0.0013963763997009236\n",
            "0.000396364534867405\n",
            "0.001032471465757773\n",
            "0.0005079380863978434\n",
            "0.0014209721271940365\n",
            "0.0010722493232441202\n",
            "0.00014527078078781813\n",
            "0.000819214863490428\n",
            "0.0001802876779937402\n",
            "0.0012631325711229997\n",
            "0.0005514257727647363\n",
            "0.0009033443497689176\n",
            "0.0006750001066167024\n",
            "0.0009006562507851733\n",
            "0.0015035889173579228\n",
            "0.00036965937599924134\n",
            "0.0003013362795278283\n",
            "0.0004926409897746401\n",
            "0.0005972058756593724\n",
            "0.0011927396295821097\n",
            "0.0009415377104622608\n",
            "0.0006678278411735723\n",
            "0.0009825109426769782\n",
            "0.0018811151037164213\n",
            "0.0015596321567270344\n",
            "0.0011346105985002148\n",
            "0.0008450482387232477\n",
            "0.0005575331095698732\n",
            "0.001336400865280658\n",
            "0.0015824368809374105\n",
            "0.0010817892714195397\n",
            "0.001125872070508871\n",
            "0.0013776654497197776\n",
            "0.001139783522716517\n",
            "0.0003630881359300386\n",
            "0.001012562078866678\n",
            "0.0005196503000104384\n",
            "0.0010327499825855094\n",
            "0.0005056266659329436\n",
            "0.0015735600973553533\n",
            "0.0005315214248973836\n",
            "0.0014761647035575164\n",
            "0.0011527705453117972\n",
            "0.0009599582678973586\n",
            "0.0019053953679637162\n",
            "0.0014257383458213633\n",
            "0.0002300964584549219\n",
            "0.00016453358196429226\n",
            "0.0012707350686086034\n",
            "0.0004435940909763319\n",
            "0.0013581300320286457\n",
            "0.0003786279508892718\n",
            "0.0006068621261250531\n",
            "0.0006188855287916481\n",
            "0.0011727253730898853\n",
            "0.00048138494380105387\n",
            "0.00014034024834333713\n",
            "0.0007856406927600838\n",
            "0.0005024480921145125\n",
            "0.0010013062441622117\n",
            "0.0005279906906885252\n",
            "0.0010630846415333908\n",
            "0.00044902684018006885\n",
            "0.001385505809870926\n",
            "0.0006761133132273938\n",
            "0.0009381783017722894\n",
            "0.0010150866704068384\n",
            "0.000373322386537519\n",
            "0.0007081128187156845\n",
            "0.0006713294597587159\n",
            "0.0008829087568456951\n",
            "0.0010471631627689854\n",
            "0.0007758189488856747\n",
            "0.0018277139328756083\n",
            "0.0009582606626181512\n",
            "0.0006269383759582943\n",
            "0.0017252468333515485\n",
            "0.00023177646804771582\n",
            "0.0006433366479029765\n",
            "0.00018290811673600134\n",
            "0.00047365692812436104\n",
            "0.0001339339639393681\n",
            "0.000726394550673007\n",
            "0.0010135684034494727\n",
            "0.00038254943988774525\n",
            "0.0008628014100668646\n",
            "0.00019598048678343616\n",
            "0.001243916506931742\n",
            "0.0007003693465353476\n",
            "0.0022658078214049444\n",
            "0.002080907313085225\n",
            "0.0007796127620358188\n",
            "0.001161388545829518\n",
            "0.0014940998017440484\n",
            "0.0008948490353067872\n",
            "0.0010656659445266703\n",
            "0.0008015211429763369\n",
            "0.0003291570834436572\n",
            "0.0002566306166980502\n",
            "0.0004357796180143197\n",
            "0.000781052976731494\n",
            "0.000607160644855036\n",
            "0.001327171297010707\n",
            "0.0011428837909224546\n",
            "0.0009094627388240436\n",
            "0.0009016568762229296\n",
            "0.0016775541532306406\n",
            "0.0004514939100934754\n",
            "0.0007991309232372624\n",
            "0.00032587776100111864\n",
            "0.0006777888007659485\n",
            "0.0012644333322114347\n",
            "0.0009378658668763196\n",
            "0.00032149188340135644\n",
            "0.001022319559321006\n",
            "0.0010071169645599833\n",
            "0.0009004282058107853\n",
            "0.0010741858338120273\n",
            "0.0012013566304382981\n",
            "0.0004269200403426758\n",
            "0.0006992996839533164\n",
            "0.00031625493479165475\n",
            "0.0005006118757744798\n",
            "0.0015586505452077782\n",
            "0.0005875398781671191\n",
            "0.0021191671080971206\n",
            "0.0007142427340201618\n",
            "0.0007992181512909348\n",
            "0.0009799653308935272\n",
            "0.00020925853659938378\n",
            "0.0009934950550926228\n",
            "0.0004649562614769343\n",
            "0.00035566507274002984\n",
            "0.0005790930194912257\n",
            "0.0005265325297869032\n",
            "0.0002351715468587122\n",
            "0.0007011907213445462\n",
            "0.0013716178977801951\n",
            "error final: 0.0008346082460514914\n"
          ]
        }
      ],
      "source": [
        "f = lambda params: loss(params, batch_size = 5)\n",
        "\n",
        "params_opt = ADAM(params, f)\n",
        "\n",
        "print(f\"error final: {loss(params_opt)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aq1aV5BXBWZ"
      },
      "source": [
        "### **Ejercicio 2: Aproximación de esperanzas condicionales vía redes neuronales**\n",
        "\n",
        "Sean $X$, $Y$ variables aleatorias y $f$ una función continua, luego es sabido de clases que el problema de encontrar una función que minimice el error cuadrático medio\n",
        "\n",
        "$$  \\min_{f} \\mathbb{E} [(Y - f(X))^2] $$\n",
        "\n",
        "Viene dado por\n",
        "\n",
        "$$ f(x) = \\mathbb{E} [Y \\, | \\, X = x] $$\n",
        "\n",
        "El objetivo de este ejercicio es ver numéricamente como una red neuronal entrenada para minimizar el error cuadrático medio de una muestra de puntos $\\{x_i, y_i \\}$ tales que $f(x_i ) = y_i$, con $f$ desconocida, en realidad se aproxima a la esperanza condicional con $X$ e $Y$ tales que $x_i \\sim X$, $y_i \\sim Y$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mos_hb0vY0zH"
      },
      "source": [
        "Para este ejercicio consideremos $X$ con ley $\\text{Unif}(-1,1)$, la función que buscamos aproximar será\n",
        "\n",
        "$$ f(x) = e^{-2 x^2}$$\n",
        "\n",
        "Y la ley de $Y$ supongamos que es $f(X) \\, + \\, \\text{batch_size}(0, 0.1^2)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjLOSretZ0Kr"
      },
      "source": [
        "#### **Ejercicio 2.1: Generar datos de entrenamiento**\n",
        "\n",
        "Samplee 100 puntos de la ley de $X$ dada antes y con ello obtenga 100 muestras aleatorias correspondientes de $Y$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "azFdzddaZzuS"
      },
      "outputs": [],
      "source": [
        "# Tu solución aquí"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFdzHs9NaV-B"
      },
      "source": [
        "#### **Ejercicio 2.2: Cálculo de la esperanza condicional vía Montecarlo**\n",
        "\n",
        "En este caso como es sabida la ley de $Y$ vía la función $f$ (en la realidad todo esto es desconocido) se puede calcular la esperanza condicional vía método de Montecarlo. Cree una función en Python que dado un $x \\in [-1, 1]$ y una cantidad de muestras para la aproximación de Montecarlo, digamos $M$, calcule\n",
        "\n",
        "$$ \\mathbb{E} [Y \\, | \\, X = x] \\approx \\hat f = \\frac{1}{M} \\sum_{j=1}^M f(x) + w_j $$\n",
        "\n",
        "Donde los $w_j$ vienen sampleados desde una $batch_size(0, 0.1^2)$. Realice 3 gráficos de $\\hat f$ en $[-1, 1]$ uno utilizando $M=10$, $M=100$, $M=1000$ ¿qué observa cuando $M$ aumenta?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "aO8v4nLVWS3Y"
      },
      "outputs": [],
      "source": [
        "# Tu solución aquí"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AekxEJtxbe-i"
      },
      "source": [
        "#### **Ejercicio 2.3: Observando la aproximación de una red neuronal**\n",
        "\n",
        "Entrene una red neuronal de una sola capa oculta con pérdida cuadrática para que ajuste a los datos que usted generó en el ejercicio 2.1, puede utilizar la función de pérdida y el ancho que más le acomode (o que mejores resultados le entregue). Grafique la predicción de la red neuronal en $[-1, 1]$ y compare con el resultado del ejercicio 2.2.\n",
        "\n",
        "*Indicación: Puede utilizar el código creado en el ejercicio 1, o bien, utilizar alguna librería como Pytorch, Tensorflow, etc.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "Etm5cPCoecZV"
      },
      "outputs": [],
      "source": [
        "# Tu solución aquí"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
