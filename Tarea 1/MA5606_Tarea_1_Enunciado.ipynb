{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUNbsNbwOTvx"
      },
      "source": [
        "## **MA5606 Tópicos Matemáticos en Aprendizaje de Máquinas, Redes Neuronales y Aprendizaje Profundo**\n",
        "\n",
        "### **Tarea 1: Redes neuronales feedfoward y PINNs**\n",
        "\n",
        "**Profesores: Claudio Muñoz y Joaquín Fontbona**\n",
        "\n",
        "**Auxiliares: Javier Maass y Diego Olguín**\n",
        "\n",
        "**Nombres integrantes: COMPLETAR**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxGdNKqBdpv_"
      },
      "source": [
        "**Instrucciones:**\n",
        "\n",
        "- **Fecha de entrega:** **26 de abril de 2024, a las 23:59.**\n",
        "\n",
        "- **Importante:** Si trabaja desde el link de Google Colab (muy recomendable para trabajar con DeepXDE) debe hacer un copia en su Drive antes de trabajar, de lo contrario se podrían no guardar sus códigos.\n",
        "\n",
        "- Debe entregar un Jupyter Notebook (archivo .ipynb) con sus código en Python. Le pueden ser de mucha utilidad los códigos vistos en la actividad práctica.\n",
        "\n",
        "- Sus códigos deben estar comentados y ordenados. Además, en formato texto debe colocar todas sus conclusiones y resultados pedidos que deban ser redactados.\n",
        "\n",
        "- En todos los ejercicios se le pide hacer al menos un gráfico. Los gráficos que realicen deben ser claros, con títulos y nombres en los ejes, junto con leyendas si es que corresponde."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0Ln5xbD8OQB7"
      },
      "outputs": [],
      "source": [
        "# Librerías\n",
        "\n",
        "# Numpy y matplotlib, junto con seaborn, para gráficos un poco mejores\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Puede ser útil para hacer gráficos con barras de colores\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_theme()\n",
        "\n",
        "# PyTorch y módulos que serán necesario\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nNotas:\\n- Un modulo de PyTorch es una red neuronal creada con PyTorch.\\n- nn.Module es la clase base para todos los módulos de PyTorch.\\n- nn.ModuleList es similar a las listas de python diseñada específicamente para almacenar modulos.\\n- nn.Linear(in_features(int), out_features(int)) crea una transformación afín desde una capa de in_features dimensiones a una capa de out_features dimensiones (y=xA^T + b).\\n- super().__init__() llama al constructor de la clase base. Es necesario para cualquier modulo de PyTorch.\\n- forward describe cómo se calcula la salida de la red a partir de la entrada.\\n'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Clase para crear redes neuronales\n",
        "class NeuralNetwork(nn.Module):\n",
        "    \"\"\"\n",
        "    Clase que define una red neuronal con una cantidad de capas y neuronas por capa definida por el usuario.\n",
        "    Es una subclase de nn.Module, la clase base para todos los módulos de PyTorch.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim_input: int,\n",
        "        dim_output: int,\n",
        "        n_hidden_layers: int,\n",
        "        width: int,\n",
        "        activation: callable,\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Constructor de la clase, que recibe los parámetros necesarios para crear una red neuronal.\n",
        "\n",
        "        Args:\n",
        "            - dim_input (int): Dimensión de la entrada.\n",
        "            - dim_output (int): Dimensión de la salida.\n",
        "            - n_hidden_layers (int): Número de capas internas.\n",
        "            - wide (int): Ancho de las capas internas.\n",
        "            - activation (callable): Función de activación.\n",
        "\n",
        "        Returns:\n",
        "            - None\n",
        "\n",
        "        Rasies:\n",
        "            - AssertionError: Si dim_input, dim_output, n_hidden_layers o wide no son enteros positivos.\n",
        "            - AssertionError: Si activation no es una función.\n",
        "        \"\"\"\n",
        "        super().__init__()  # Inicia el constructor de la clase base (nn.Module)\n",
        "\n",
        "        for int_input, name in zip(\n",
        "            [dim_input, dim_output, n_hidden_layers, width],\n",
        "            [\"dim_input\", \"dim_output\", \"n_hidden_layers\", \"width\"],\n",
        "        ):\n",
        "            assert (\n",
        "                isinstance(int_input, int) and int_input > 0\n",
        "            ), f\"Error en los parámetros de la red. Error: {int_input} ({name}) debe ser un entero positivo.\"\n",
        "        assert callable(\n",
        "            activation\n",
        "        ), \"Error en los parámetros de la red. Error: activation debe ser una función.\"\n",
        "\n",
        "        self.first_layer = nn.Linear(dim_input, width)\n",
        "        self.inner_layers = nn.ModuleList(\n",
        "            [nn.Linear(width, width) for _ in range(n_hidden_layers - 1)]\n",
        "        )\n",
        "        self.last_layer = nn.Linear(width, dim_output)\n",
        "\n",
        "        self.activation = activation\n",
        "\n",
        "    def forward(self, x) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Describe cómo se calcula la salida de la red a partir de la entrada.\n",
        "\n",
        "        Args:\n",
        "            - x (torch.Tensor): Tensor de entrada.\n",
        "\n",
        "        Returns:\n",
        "            - torch.Tensor: Tensor de salida.\n",
        "        \"\"\"\n",
        "        x = self.activation(self.first_layer(x))\n",
        "        for layer in self.inner_layers:\n",
        "            x = self.activation(layer(x))\n",
        "        x = self.last_layer(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Notas:\n",
        "- Un modulo de PyTorch es una red neuronal creada con PyTorch.\n",
        "- nn.Module es la clase base para todos los módulos de PyTorch.\n",
        "- nn.ModuleList es similar a las listas de python diseñada específicamente para almacenar modulos.\n",
        "- nn.Linear(in_features(int), out_features(int)) crea una transformación afín desde una capa de in_features dimensiones a una capa de out_features dimensiones (y=xA^T + b).\n",
        "- super().__init__() llama al constructor de la clase base. Es necesario para cualquier modulo de PyTorch.\n",
        "- forward describe cómo se calcula la salida de la red a partir de la entrada.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7r-Fb47PG3s"
      },
      "source": [
        "## **Ejercicio 1**\n",
        "\n",
        "El objetivo de este ejercicio es estudiar la aproximación vía redes neuronales del problema de frontera\n",
        "\n",
        "$$ y''(x) + \\frac{\\pi^2}{4} y(x) = 0 $$\n",
        "$$ y(-1) = y(1) = 0, \\, y(0) = 1$$\n",
        "\n",
        "Para ello utilice redes de 1 capa oculta de ancho $N$, usando $N = \\{ 10, 20, 30, 100\\}$. Entrene la red con 600 iteraciones del algoritmo ``Adam``.\n",
        "\n",
        "En cada caso grafique la evolución de la función de pérdida en las iteraciones de entrenamiento, además de la red evaluada en puntos en el intervalo $[-1,1]$ y compare con la solución analítica:\n",
        "\n",
        "$$ y(x) = \\cos \\left (\\frac{\\pi}{2} x \\right ) $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3nXEQlOhK_0X"
      },
      "outputs": [],
      "source": [
        "# Parametros\n",
        "gamma = 0.01 # Learning rate.\n",
        "N = [10, 20, 30, 100] # Anchos de las NN.\n",
        "resolution = 100  # Cardinalidad de la partición de [-1,1].\n",
        "iters = 600  # Iteraciones de entrenamiento.\n",
        "\n",
        "# Listas de redes y optimizadores\n",
        "neural_list = nn.ModuleList()\n",
        "optimizer_list = []\n",
        "\n",
        "# Creación de las redes y optimizadores\n",
        "for n in N:\n",
        "    NN = NeuralNetwork(\n",
        "        dim_input=1, dim_output=1, n_hidden_layers=1, width=n, activation=F.tanh\n",
        "    )\n",
        "    neural_list.append(NN)\n",
        "\n",
        "    optimizer = optim.Adam(NN.parameters(), lr=gamma)\n",
        "    optimizer_list.append(optimizer)\n",
        "\n",
        "\n",
        "# Iremos guardando la pérdida en cada iteración\n",
        "loss_record = []\n",
        "\n",
        "X = torch.rand(resolution, 1)\n",
        "\n",
        "\n",
        "def calc_loss(NN):\n",
        "    # Predicción de la red\n",
        "    output = NN(X)\n",
        "\n",
        "    # Calculo de la función de pérdida, en este caso es en media cuadrática\n",
        "    loss = nn.MSELoss(output, y)\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DMLdiY3RjId"
      },
      "source": [
        "## **Ejercicio 2**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ho8aesDRAwr2"
      },
      "source": [
        "Veremos nuevamente el problema de EDP de Helmholtz\n",
        "\n",
        "$$ -\\Delta u - k_0^2 u = f, \\quad \\Omega = (0,1)^2 $$\n",
        "$$ u = 0, \\quad ∂ Ω $$\n",
        "\n",
        "Que tiene solución analítica\n",
        "\n",
        "$$ u(x, y) =  \\sin (k_0 x) \\sin (k_0 y)$$\n",
        "\n",
        "Cuando $f(x,y) = k_0^2 \\sin (k_0 x) \\sin (k_0 y)$. Considere $k_0 = 2 n \\pi$ y entrene una red neuronal de 3 capas, 100 neuronas por capa, función de activación seno y 3000 iteraciones del optimizador Adam, que resuelva el problema para $n \\in \\{ 1, 3, 5 \\}$. Grafique la función de pérdida en función de las iteraciones de entrenamiento y el resultado de la red, comparando este con la solución analítica. ¿Qué resultado observa para los distintos $n$ propuestos?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3yq5QQlGBB-4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using backend: pytorch\n",
            "Other supported backends: tensorflow.compat.v1, tensorflow, jax, paddle.\n",
            "paddle supports more examples now and is recommended.\n"
          ]
        }
      ],
      "source": [
        "# Instalamos e importamos la librería\n",
        "import deepxde as dde\n",
        "\n",
        "\n",
        "# Importamos Tensorflow, que es el backend que utilizaremos\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "YgaYPiXYLQfR"
      },
      "outputs": [],
      "source": [
        "# Solución!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRVZDx4YaL8y"
      },
      "source": [
        "### **Ejercicio 3**\n",
        "\n",
        "Considere el problema de Poisson\n",
        "\n",
        "$$ -\\Delta u = x(1-x) + y(1-y), \\quad \\Omega = (0,1)^2 $$\n",
        "$$ u = 0, \\quad ∂ Ω $$\n",
        "\n",
        "Que tiene solución analítica\n",
        "\n",
        "$$ u(x, y) = \\frac{1}{2} x(1-x)y(1-y)$$\n",
        "\n",
        "Entrene una red neuronal que aproxime la solución al problema, para ello considere una red de 3 capas, 100 neuronas por cada, función de activatión tangente hiperbólica y 500 iteraciones del optimizador Adam. Grafique la función de pérdida en función de las iteraciones de entrenamiento y el resultado de la red, comparando este con la solución analítica del problema.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "cPDkUQCXLS_7"
      },
      "outputs": [],
      "source": [
        "# Solución!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
